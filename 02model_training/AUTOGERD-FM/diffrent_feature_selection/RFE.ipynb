{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be4ae4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200f808d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('gerd.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80890cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Divide features and labels, remove and replace miscellaneous items in the features\n",
    "X = df.drop(columns=['Name','gender', 'LES上缘位置cm', 'LES位置(距鼻孔)cm','LES下缘位置cm','UES静息压mmHg', 'UES残余压mmHg', '大缺损收缩(次)',\n",
    "       'UES上缘位置cm', '小缺损收缩(次)', 'UES下缘位置cm','UES长度cm','UES位置(距鼻孔)cm','age', 'birthday', '检查时间', '主诉','诊断结果','PIP','label'])\n",
    "X.replace('YES',1,inplace=True)\n",
    "X.replace('NO',0,inplace=True)\n",
    "X.replace('1.#J',1.0,inplace=True)\n",
    "X.replace('--',0,inplace=True)\n",
    "X.replace('-',0,inplace=True)\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9451b9b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n",
    "# estimator = SVR(kernel=\"linear\")\n",
    "estimator = RandomForestClassifier(oob_score=True,random_state=123,bootstrap=True)\n",
    "\n",
    "# estimator = grid_rf.best_estimator_\n",
    "selector = RFECV(estimator, step=1, cv=5)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "selector.support_\n",
    "selector.ranking_\n",
    "X = X.loc[:,selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05320fb5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# dataset split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.8,random_state= 123, stratify = \n",
    "                                                 y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5435f3ca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(X_train)\n",
    "X_train = standard_scaler.transform(X_train)\n",
    "X_test = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d1a98",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Modeling with different models\n",
    "'''KNN'''\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\n",
    "    'n_neighbors' : [n for n in range(1,50)],\n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'p': [i for i in range(1,7)]\n",
    "}\n",
    "grid_knn = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    param_grid = params,\n",
    "    n_jobs=-1,\n",
    "    cv = 10\n",
    ")\n",
    "grid_knn.fit(X_train,y_train)\n",
    "\n",
    "'''LR'''\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline_lr = Pipeline([\n",
    "    ('PolynomialFeatures', PolynomialFeatures()),\n",
    "    ('LR', LogisticRegression())\n",
    "    \n",
    "])\n",
    "params_lr = {\n",
    "    'LR__C': [0.0001,0.001,0.01,0.1,2,3,5,10,15,20,25,30,40,50,60,70,80,90,100,1000],\n",
    "    'LR__penalty': ['l2','l1'],\n",
    "    'LR__solver': ['liblinear'],\n",
    "    'LR__max_iter':[10000],\n",
    "    'PolynomialFeatures__degree': [i for i in range(1, 3)]\n",
    "}\n",
    "grid_lr = GridSearchCV(\n",
    "    estimator=pipeline_lr,\n",
    "    param_grid=params_lr,\n",
    "    n_jobs = -1,\n",
    "    cv = 10\n",
    ")\n",
    "\n",
    "grid_lr.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "'''SVM'''\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "pipeline_svc = Pipeline([\n",
    "    ('PolynomialFeatures', PolynomialFeatures()),\n",
    "    ('SVC', SVC(probability=True))\n",
    "    \n",
    "])\n",
    "params_svm = {\n",
    "    'SVC__C': [0.01,0.1,2,3,5,10,15,20,25,30,40,50,60,70,80,90,100],\n",
    "    'SVC__gamma': [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000],\n",
    "    'SVC__kernel': ['rbf'],\n",
    "#     'SVC__probability':['True'],\n",
    "    'PolynomialFeatures__degree': [i for i in range(1, 3)]\n",
    "}\n",
    "grid_svm = GridSearchCV(\n",
    "    estimator=pipeline_svc,\n",
    "    param_grid=params_svm,\n",
    "    n_jobs = -1,\n",
    "    cv = 10\n",
    ")\n",
    "grid_svm.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "'''Voting'''\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "clf = [\n",
    "    KNeighborsClassifier(),\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    SVC(probability=True)\n",
    "]\n",
    "vclf = VotingClassifier(\n",
    "    estimators = [\n",
    "        ('knn', clf[0]),\n",
    "        ('lr', clf[1]),\n",
    "        ('dt', clf[2]),\n",
    "        ('svm',clf[3])\n",
    "    ],\n",
    "    voting = 'soft'\n",
    ")\n",
    "params = {\n",
    "    'knn__n_neighbors' : [n for n in range(1,50)],\n",
    "    'knn__weights' : ['uniform', 'distance'],\n",
    "    'knn__p': [i for i in range(1,7)],\n",
    "    'lr__C': [0.0001,0.001,0.01,0.1,2,3,5,10,15,20,25,30,40,50,60,70,80,90,100,1000],\n",
    "    'lr__penalty': ['l2','l1'],\n",
    "    'lr__solver': ['liblinear'],\n",
    "    'lr__max_iter':[10000],\n",
    "    'lr__multi_class':['multinomial','ovr'],\n",
    "    'svm__C': [0.01,0.1,2,3,5,10,15,20,25,30,40,50,60,70,80,90,100],\n",
    "    'svm__gamma': [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000],\n",
    "    'svm__kernel': ['rbf'],\n",
    "    'dt__max_depth': [i for i in range(3,10)],\n",
    "    'dt__min_samples_split' : [i for i in range(3,10)],\n",
    "    'dt__min_samples_leaf': [i for i in range(3,10)],\n",
    "    'dt__criterion':['gini', 'entropy', 'log_loss']\n",
    "    }\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    " \n",
    "random_cv = RandomizedSearchCV( \n",
    "    vclf, params, n_iter=10000, cv=10, scoring=\"neg_log_loss\", n_jobs=-1\n",
    ")\n",
    "random_cv.fit(X_train,y_train)\n",
    "\n",
    "'''RF'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(oob_score=True,random_state=321,bootstrap=True)\n",
    "params_rf = {\n",
    "    'n_estimators': [10,20,30,50,70,100,125,150,175,200,250],\n",
    "    'max_samples':[40,50,60,70,80,90,100,120,140],\n",
    "    'max_depth': [i for i in range(3,10)],\n",
    "    'min_samples_split' : [i for i in range(3,10)],\n",
    "    'min_samples_leaf': [i for i in range(3,10)],\n",
    "    'criterion':['gini', 'entropy', 'log_loss']\n",
    "}\n",
    "grid_rf = GridSearchCV(\n",
    "    estimator=rf_clf,\n",
    "    param_grid=params_rf,\n",
    "    n_jobs = -1,\n",
    "    cv = 10\n",
    ")\n",
    "grid_rf.fit(X_train,y_train)\n",
    "\n",
    "'''Bagging'''\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagging = BaggingClassifier(\n",
    "    n_estimators = 200,\n",
    "    bootstrap=True,\n",
    "    oob_score=True,\n",
    "    bootstrap_features=True,\n",
    "    random_state=123\n",
    ")\n",
    "params_bagging = {\n",
    "    'estimator':[DecisionTreeClassifier(),SVC(probability=True),LogisticRegression(),KNeighborsClassifier()],\n",
    "    'max_features':[i for i in range(1,10)],\n",
    "    'max_samples':[1,3,5,7,10,20,30,40,50,60,70,80,90,100,120],\n",
    "#     'max_depth': [i for i in range(3,10)],\n",
    "#     'min_samples_split' : [i for i in range(3,10)],\n",
    "#     'min_samples_leaf': [i for i in range(3,10)],\n",
    "#     'criterion':['gini', 'entropy', 'log_loss']\n",
    "}\n",
    "random_bagging = GridSearchCV( \n",
    "    bagging, params_bagging,  cv=10,  n_jobs=16 \n",
    ")\n",
    "random_bagging.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff979f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# graphing\n",
    "fig,ax= plt.subplots()\n",
    "\n",
    "bwith = 1\n",
    "ax = plt.gca()\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(True)\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "ax.spines['bottom'].set_linewidth(bwith)\n",
    "ax.spines['left'].set_linewidth(bwith)\n",
    "ax.spines['top'].set_linewidth(bwith)\n",
    "ax.spines['right'].set_linewidth(bwith)\n",
    "ax.spines['bottom'].set_linestyle(\"-\")\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_linestyle(\"-\")\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['top'].set_linestyle(\"-\")\n",
    "ax.spines['top'].set_color('black')\n",
    "ax.spines['right'].set_linestyle(\"-\")\n",
    "ax.spines['right'].set_color('black')\n",
    "ax.set_facecolor(\"white\")\n",
    "ax.minorticks_on()\n",
    "ax.tick_params(axis=\"both\", which=\"major\", direction=\"out\", width=1, length=5)\n",
    "ax.tick_params(axis=\"both\", which=\"minor\", direction=\"out\", width=1, length=3)\n",
    "\n",
    "\n",
    "y_score_knn = grid_knn.best_estimator_.predict_proba(X_test)\n",
    "auc_knn = roc_auc_score(y_test,y_score_knn[:,1])\n",
    "fpr_knn,tpr_knn,thres_knn = roc_curve(y_test,y_score_knn[:,1])\n",
    "plt.plot(fpr_knn,tpr_knn,label = 'KNN AUC = %0.3f' % auc_knn)\n",
    "\n",
    "y_decition_lr = grid_lr.best_estimator_.decision_function(X_test)\n",
    "auc_log = roc_auc_score(y_test,y_decition_lr)\n",
    "fpr_log,tpr_log,thres_log = roc_curve(y_test,y_decition_lr)\n",
    "plt.plot(fpr_log,tpr_log,label = 'LR AUC = %0.3f' % auc_log)\n",
    "\n",
    "y_decition_vo = random_cv.best_estimator_.predict_proba(X_test)\n",
    "auc_vo = roc_auc_score(y_test,y_decition_vo[:,1])\n",
    "fpr_vo,tpr_vo,thres_vo = roc_curve(y_test,y_decition_vo[:,1])\n",
    "plt.plot(fpr_vo,tpr_vo,label = 'Voting AUC = %0.3f' % auc_vo)\n",
    "\n",
    "y_decition_svm = grid_svm.best_estimator_.decision_function(X_test)\n",
    "auc_svm = roc_auc_score(y_test,y_decition_svm)\n",
    "fpr_svm,tpr_svm,thres_svm = roc_curve(y_test,y_decition_svm)\n",
    "plt.plot(fpr_svm,tpr_svm,label = 'SVM AUC = %0.3f' % auc_svm)\n",
    "                                      \n",
    "y_decition_rf = grid_rf.best_estimator_.predict_proba(X_test)\n",
    "auc_rf = roc_auc_score(y_test,y_decition_rf[:,1])\n",
    "fpr_rf,tpr_rf,thres_rf = roc_curve(y_test,y_decition_rf[:,1])\n",
    "plt.plot(fpr_rf,tpr_rf,label = 'Random Forest AUC = %0.3f' % auc_rf)\n",
    "\n",
    "\n",
    "y_decition_bagging = random_bagging.best_estimator_.predict_proba(X_test)\n",
    "auc_bagging = roc_auc_score(y_test,y_decition_bagging[:,1])\n",
    "fpr_bagging,tpr_bagging,thres_bagging = roc_curve(y_test,y_decition_bagging[:,1])\n",
    "plt.plot(fpr_bagging,tpr_bagging,label = 'Bagging AUC = %0.3f' % auc_bagging)\n",
    "\n",
    "plt.grid(False)\n",
    "\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend()\n",
    "plt.title('RFE')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
